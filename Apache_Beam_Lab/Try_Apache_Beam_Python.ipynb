{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNKIMlEDZ_Vw"
   },
   "source": [
    "# Apache Beam Text Analysis Pipeline\n",
    "\n",
    "This notebook demonstrates an enhanced text analysis pipeline using Apache Beam with the [DirectRunner](https://beam.apache.org/documentation/runners/direct/). We'll perform advanced word counting, filtering, and statistical analysis on text data.\n",
    "\n",
    "**Key Features:**\n",
    "- Case-insensitive word counting\n",
    "- Stop word filtering\n",
    "- Word length analysis\n",
    "- Top N word extraction\n",
    "- Statistical summaries\n",
    "\n",
    "To navigate through different sections, use the table of contents. From **View** drop-down list, select **Table of contents**.\n",
    "\n",
    "To run a code cell, click the **Run cell** button at the top left of the cell, or select it and press **`Shift+Enter`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz6KSQ13_3Rr"
   },
   "source": [
    "# Environment Setup\n",
    "\n",
    "This section sets up the development environment by installing Apache Beam and preparing the input data. We'll download a Shakespeare text file to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "GOOk81Jj_yUy",
    "outputId": "d283dfb2-4f51-4fec-816b-f57b0cb9b71c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> mkdir -p data\n",
      "\n",
      ">> gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/\n",
      "Copying gs://dataflow-samples/shakespeare/kinglear.txt...\n",
      "/ [1 files][153.6 KiB/153.6 KiB]                                                \n",
      "Operation completed over 1 objects/153.6 KiB.                                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run and print a shell command.\n",
    "def run(cmd):\n",
    "  print('>> {}'.format(cmd))\n",
    "  !{cmd}\n",
    "  print('')\n",
    "\n",
    "# Install apache-beam.\n",
    "# run('pip install --quiet apache-beam')\n",
    "\n",
    "# Copy the input file into the local file system.\n",
    "run('mkdir -p data')\n",
    "run('gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-HubCrk-h_G"
   },
   "source": [
    "# Enhanced Text Analysis Pipeline\n",
    "\n",
    "This pipeline performs multiple text analysis operations:\n",
    "1. **Case-insensitive word counting** - Normalizes all words to lowercase\n",
    "2. **Stop word filtering** - Removes common words that don't add meaning\n",
    "3. **Word length analysis** - Calculates statistics about word lengths\n",
    "4. **Top N extraction** - Identifies the most frequent meaningful words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1173
    },
    "id": "x_D7sxUHFzUp",
    "outputId": "44c926df-aa4a-4bea-9247-27c7cb537717"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> head -n 200 outputs/part-00000-of-*\n",
      "('KING', 243)\n",
      "('LEAR', 236)\n",
      "('DRAMATIS', 1)\n",
      "('PERSONAE', 1)\n",
      "('king', 65)\n",
      "('of', 447)\n",
      "('Britain', 2)\n",
      "('OF', 15)\n",
      "('FRANCE', 10)\n",
      "('DUKE', 3)\n",
      "('BURGUNDY', 8)\n",
      "('CORNWALL', 63)\n",
      "('ALBANY', 67)\n",
      "('EARL', 2)\n",
      "('KENT', 156)\n",
      "('GLOUCESTER', 141)\n",
      "('EDGAR', 126)\n",
      "('son', 29)\n",
      "('to', 438)\n",
      "('Gloucester', 26)\n",
      "('EDMUND', 99)\n",
      "('bastard', 7)\n",
      "('CURAN', 6)\n",
      "('a', 366)\n",
      "('courtier', 1)\n",
      "('Old', 13)\n",
      "('Man', 11)\n",
      "('tenant', 3)\n",
      "('Doctor', 12)\n",
      "('Fool', 73)\n",
      "('OSWALD', 53)\n",
      "('steward', 2)\n",
      "('Goneril', 12)\n",
      "('A', 51)\n",
      "('Captain', 12)\n",
      "('employed', 1)\n",
      "('by', 69)\n",
      "('Edmund', 32)\n",
      "('Gentleman', 48)\n",
      "('attendant', 1)\n",
      "('on', 93)\n",
      "('Cordelia', 22)\n",
      "('Herald', 6)\n",
      "('Servants', 9)\n",
      "('Cornwall', 12)\n",
      "('First', 7)\n",
      "('Servant', 11)\n",
      "('Second', 4)\n",
      "('Third', 4)\n",
      "('GONERIL', 71)\n",
      "('REGAN', 86)\n",
      "('daughters', 24)\n",
      "('Lear', 17)\n",
      "('CORDELIA', 42)\n",
      "('Knights', 2)\n",
      "(\"Lear's\", 4)\n",
      "('train', 9)\n",
      "('Captains', 1)\n",
      "('Messengers', 1)\n",
      "('Soldiers', 7)\n",
      "('and', 594)\n",
      "('Attendants', 8)\n",
      "('Knight', 8)\n",
      "('Messenger', 10)\n",
      "('SCENE', 27)\n",
      "('ACT', 26)\n",
      "('I', 622)\n",
      "('King', 3)\n",
      "('palace', 4)\n",
      "('Enter', 63)\n",
      "('thought', 15)\n",
      "('the', 786)\n",
      "('had', 35)\n",
      "('more', 75)\n",
      "('affected', 2)\n",
      "('Duke', 8)\n",
      "('Albany', 6)\n",
      "('than', 51)\n",
      "('It', 19)\n",
      "('did', 19)\n",
      "('always', 2)\n",
      "('seem', 8)\n",
      "('so', 113)\n",
      "('us', 51)\n",
      "('but', 84)\n",
      "('now', 53)\n",
      "('in', 271)\n",
      "('division', 3)\n",
      "('kingdom', 12)\n",
      "('it', 171)\n",
      "('appears', 4)\n",
      "('not', 266)\n",
      "('which', 44)\n",
      "('dukes', 4)\n",
      "('he', 137)\n",
      "('values', 1)\n",
      "('most', 43)\n",
      "('for', 123)\n",
      "('equalities', 1)\n",
      "('are', 117)\n",
      "('weighed', 1)\n",
      "('that', 250)\n",
      "('curiosity', 3)\n",
      "('neither', 7)\n",
      "('can', 37)\n",
      "('make', 46)\n",
      "('choice', 4)\n",
      "(\"either's\", 1)\n",
      "('moiety', 1)\n",
      "('Is', 27)\n",
      "('this', 187)\n",
      "('your', 205)\n",
      "('my', 402)\n",
      "('lord', 96)\n",
      "('His', 17)\n",
      "('breeding', 3)\n",
      "('sir', 94)\n",
      "('hath', 52)\n",
      "('been', 29)\n",
      "('at', 57)\n",
      "('charge', 3)\n",
      "('have', 194)\n",
      "('often', 4)\n",
      "('blushed', 1)\n",
      "('acknowledge', 2)\n",
      "('him', 198)\n",
      "('am', 84)\n",
      "('brazed', 1)\n",
      "('cannot', 18)\n",
      "('conceive', 1)\n",
      "('you', 401)\n",
      "('Sir', 21)\n",
      "('young', 10)\n",
      "(\"fellow's\", 1)\n",
      "('mother', 4)\n",
      "('could', 17)\n",
      "('whereupon', 1)\n",
      "('she', 44)\n",
      "('grew', 3)\n",
      "('round', 1)\n",
      "('wombed', 1)\n",
      "('indeed', 5)\n",
      "('her', 126)\n",
      "('cradle', 1)\n",
      "('ere', 6)\n",
      "('husband', 9)\n",
      "('bed', 8)\n",
      "('Do', 23)\n",
      "('smell', 6)\n",
      "('fault', 7)\n",
      "('wish', 2)\n",
      "('undone', 1)\n",
      "('issue', 4)\n",
      "('being', 15)\n",
      "('proper', 1)\n",
      "('But', 50)\n",
      "('order', 1)\n",
      "('law', 5)\n",
      "('some', 31)\n",
      "('year', 4)\n",
      "('elder', 1)\n",
      "('who', 34)\n",
      "('yet', 45)\n",
      "('is', 192)\n",
      "('no', 92)\n",
      "('dearer', 3)\n",
      "('account', 1)\n",
      "('though', 15)\n",
      "('knave', 19)\n",
      "('came', 13)\n",
      "('something', 7)\n",
      "('saucily', 2)\n",
      "('into', 17)\n",
      "('world', 19)\n",
      "('before', 16)\n",
      "('was', 46)\n",
      "('sent', 5)\n",
      "('his', 193)\n",
      "('fair', 9)\n",
      "('there', 44)\n",
      "('good', 67)\n",
      "('sport', 3)\n",
      "('making', 3)\n",
      "('whoreson', 5)\n",
      "('must', 44)\n",
      "('be', 154)\n",
      "('acknowledged', 2)\n",
      "('know', 72)\n",
      "('noble', 18)\n",
      "('gentleman', 10)\n",
      "('No', 59)\n",
      "('My', 55)\n",
      "('Kent', 19)\n",
      "('remember', 6)\n",
      "('hereafter', 1)\n",
      "('as', 94)\n",
      "('honourable', 2)\n",
      "('friend', 19)\n",
      "('services', 5)\n",
      "('lordship', 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Configuration\n",
    "inputs_pattern = 'data/*'\n",
    "outputs_prefix = 'outputs/word_counts'\n",
    "word_length_output = 'outputs/word_lengths'\n",
    "top_words_output = 'outputs/top_words'\n",
    "\n",
    "# Define common stop words to filter out\n",
    "STOP_WORDS = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n",
    "              'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',\n",
    "              'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',\n",
    "              'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that',\n",
    "              'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they',\n",
    "              'his', 'her', 'its', 'our', 'their', 'my', 'your', 'me', 'him',\n",
    "              'us', 'them', 'what', 'which', 'who', 'whom', 'whose', 'where',\n",
    "              'when', 'why', 'how', 'all', 'each', 'every', 'both', 'few',\n",
    "              'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not',\n",
    "              'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't',\n",
    "              'can', 'will', 'just', 'don', 'should', 'now'}\n",
    "\n",
    "# Running locally in the DirectRunner.\n",
    "with beam.Pipeline() as pipeline:\n",
    "  # Step 1: Read and extract words (case-insensitive)\n",
    "  words = (\n",
    "      pipeline\n",
    "      | 'Read lines' >> beam.io.ReadFromText(inputs_pattern)\n",
    "      | 'Extract words' >> beam.FlatMap(\n",
    "          lambda line: re.findall(r\"[a-zA-Z']+\", line.lower())\n",
    "      )\n",
    "      | 'Filter empty' >> beam.Filter(lambda word: len(word) > 0)\n",
    "  )\n",
    "  \n",
    "  # Step 2: Count words (case-insensitive)\n",
    "  word_counts = (\n",
    "      words\n",
    "      | 'Pair with count' >> beam.Map(lambda word: (word, 1))\n",
    "      | 'Sum counts' >> beam.CombinePerKey(sum)\n",
    "  )\n",
    "  \n",
    "  # Step 3: Filter out stop words and short words\n",
    "  meaningful_words = (\n",
    "      word_counts\n",
    "      | 'Filter stop words' >> beam.Filter(\n",
    "          lambda word_count: word_count[0] not in STOP_WORDS and len(word_count[0]) > 2\n",
    "      )\n",
    "  )\n",
    "  \n",
    "  # Step 4: Calculate word length statistics\n",
    "  word_lengths = (\n",
    "      words\n",
    "      | 'Get word lengths' >> beam.Map(lambda word: len(word))\n",
    "      | 'Pair length with count' >> beam.Map(lambda length: (length, 1))\n",
    "      | 'Count by length' >> beam.CombinePerKey(sum)\n",
    "  )\n",
    "  \n",
    "  # Step 5: Get top 50 most frequent meaningful words\n",
    "  top_words = (\n",
    "      meaningful_words\n",
    "      | 'Sort by count' >> beam.combiners.Top.Of(50, key=lambda x: x[1])\n",
    "      | 'Flatten top list' >> beam.FlatMap(lambda x: x)\n",
    "  )\n",
    "  \n",
    "  # Write outputs\n",
    "  (\n",
    "      meaningful_words\n",
    "      | 'Format word counts' >> beam.Map(\n",
    "          lambda word_count: f\"{word_count[0]}: {word_count[1]}\"\n",
    "      )\n",
    "      | 'Write word counts' >> beam.io.WriteToText(outputs_prefix)\n",
    "  )\n",
    "  \n",
    "  (\n",
    "      word_lengths\n",
    "      | 'Format lengths' >> beam.Map(\n",
    "          lambda length_count: f\"Length {length_count[0]}: {length_count[1]} words\"\n",
    "      )\n",
    "      | 'Write lengths' >> beam.io.WriteToText(word_length_output)\n",
    "  )\n",
    "  \n",
    "  (\n",
    "      top_words\n",
    "      | 'Format top words' >> beam.Map(\n",
    "          lambda word_count: f\"{word_count[0]}: {word_count[1]}\"\n",
    "      )\n",
    "      | 'Write top words' >> beam.io.WriteToText(top_words_output)\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 60)\n",
    "print(\"TOP 30 MOST FREQUENT MEANINGFUL WORDS:\")\n",
    "print(\"=\" * 60)\n",
    "run('head -n 30 {}-00000-of-*'.format(top_words_output))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WORD LENGTH DISTRIBUTION (first 20):\")\n",
    "print(\"=\" * 60)\n",
    "run('head -n 20 {}-00000-of-*'.format(word_length_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character frequency analysis\n",
    "char_output = 'outputs/char_frequency'\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "  char_freq = (\n",
    "      pipeline\n",
    "      | 'Read lines for chars' >> beam.io.ReadFromText(inputs_pattern)\n",
    "      | 'Extract characters' >> beam.FlatMap(\n",
    "          lambda line: [char.lower() for char in line if char.isalpha()]\n",
    "      )\n",
    "      | 'Pair char with count' >> beam.Map(lambda char: (char, 1))\n",
    "      | 'Sum char counts' >> beam.CombinePerKey(sum)\n",
    "      | 'Format char frequency' >> beam.Map(\n",
    "          lambda char_count: f\"{char_count[0]}: {char_count[1]}\"\n",
    "      )\n",
    "      | 'Write char frequency' >> beam.io.WriteToText(char_output)\n",
    "  )\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHARACTER FREQUENCY ANALYSIS:\")\n",
    "print(\"=\" * 60)\n",
    "run('head -n 26 {}-00000-of-*'.format(char_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Try Apache Beam - Python",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
